{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Ad05RTheta1RSteer05Abs0FR200/preloadRARL.jl\")\n",
    "using PyCall\n",
    "using Distributions\n",
    "unshift!(PyVector(pyimport(\"sys\")[\"path\"]), \"\")\n",
    "unshift!(PyVector(pyimport(\"sys\")[\"path\"]), \"..\")\n",
    "unshift!(PyVector(pyimport(\"sys\")[\"path\"]), \"../Ad05RTheta1RSteer05Abs0FR200\")\n",
    "unshift!(PyVector(pyimport(\"sys\")[\"path\"]), \"../CommonFiles\")\n",
    "@pyimport python2juliaReuse as p2j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# policies = [\"Baseline/Rewards/b_15e3_3\",\"Retrain/Rewards/rarl\",\"Retrain/Rewards/rarlP10\",\n",
    "#             \"FSP/Rewards/nBnoTR\",\"FSP/Rewards/nBnoTRP10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = p2j.PolicyContainer()\n",
    "path = \"Data/Sep1/Ad05RTheta1RSteer05Abs0FR200/\"\n",
    "# policies = readdir(string(path,\"Policy\"))\n",
    "# pnames = []\n",
    "# for i = 1:length(policies)\n",
    "#     if policies[i] != \".DS_Store\"\n",
    "#         push!(pnames,policies[i][1:length(policies[i])-4])\n",
    "#     end\n",
    "# end\n",
    "# println(pnames)\n",
    "pnames = [\"fsp_2e3\",\"fsp_3e3\",\"fsp_4e3\"]\n",
    "include(\"../Ad05RTheta1RSteer05Abs0FR200/preloadRARL.jl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Counter\n",
    "    i::Int\n",
    "    I::Int\n",
    "    num_collision::Int\n",
    "    rate_collision::Float64\n",
    "    total_reward::Float64\n",
    "    single_reward::Float64\n",
    "    avg_reward::Float64\n",
    "    max_reward::Float64\n",
    "    min_reward::Float64\n",
    "    rewards::Array{Float64}\n",
    "    done::Bool\n",
    "    direction::Int\n",
    "    total_speed::Float64\n",
    "    single_speed::Float64\n",
    "    avg_speed::Float64\n",
    "    speeds::Array{Float64}\n",
    "    single_time::Float64\n",
    "    total_time::Float64\n",
    "    time_between_collisions::Float64\n",
    "    total_reward_d::Float64\n",
    "    single_reward_d::Float64\n",
    "    avg_reward_d::Float64\n",
    "    rewards_d::Array{Float64}\n",
    "end\n",
    "function Counter(N::Int)\n",
    "    return Counter(0,N,0,0.0,0.0,0.0,0.0,-Inf,Inf,zeros(N),false,-1,\n",
    "        0.0,0.0,0.0,zeros(N),0.0,0.0,0.0,0.0,0.0,0.0,zeros(N))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function handle_action!(pc,scene,models,roadway,counter,rarl)\n",
    "    state = get_observation(scene,models,roadway)\n",
    "    if rarl\n",
    "#         action1_arr = pc[:getAction_just](state)\n",
    "        dist = pc[:getActionDistribution_just](state)\n",
    "        action1_arr = dist[\"mean\"]\n",
    "    else\n",
    "        action1_arr = pc[:getAction_just_baseline](state)\n",
    "    end\n",
    "    action1_arr = tanh.(action1_arr)\n",
    "\n",
    "    dacc = 2*rand()-2.0\n",
    "    dsteer = 2*rand()-2.0\n",
    "    action = Egoaction(action1_arr[1],action1_arr[2],dacc,dsteer)\n",
    "    \n",
    "    done, bump = simulate_action!(action,scene,models,roadway)\n",
    "    counter.single_time += TIMESTEP\n",
    "    counter.total_time += TIMESTEP\n",
    "    reward = reward_fn(action,done,scene,models,roadway)\n",
    "    if bump\n",
    "        counter.num_collision += 1\n",
    "    else\n",
    "        counter.total_reward_d += reward\n",
    "        counter.single_reward_d += reward\n",
    "    end\n",
    "    \n",
    "    counter.total_reward += reward\n",
    "    counter.single_reward += reward\n",
    "    \n",
    "    speed = scene[1].state.v\n",
    "    counter.single_speed += speed\n",
    "    counter.total_speed += speed\n",
    "    \n",
    "    if done\n",
    "        pc[:resetPolicy](1)\n",
    "        rand_ego!(scene,models,roadway)\n",
    "        \n",
    "        counter.i += 1\n",
    "        if counter.single_reward > counter.max_reward\n",
    "            counter.max_reward = counter.single_reward\n",
    "        end\n",
    "        if counter.single_reward < counter.min_reward\n",
    "            counter.min_reward = counter.single_reward\n",
    "        end\n",
    "        if counter.i > counter.I\n",
    "            counter.done = true\n",
    "            counter.avg_reward = counter.total_reward/counter.I\n",
    "            counter.rate_collision = counter.num_collision/counter.I\n",
    "            counter.avg_reward_d = counter.total_reward_d/counter.I\n",
    "            counter.avg_speed = counter.total_speed/(counter.total_time/TIMESTEP)\n",
    "            counter.time_between_collisions = counter.total_time/counter.num_collision\n",
    "        else\n",
    "            counter.rewards[counter.i] = counter.single_reward\n",
    "            counter.rewards_d[counter.i] = counter.single_reward_d\n",
    "            counter.speeds[counter.i] = counter.single_speed/(counter.single_time/TIMESTEP)\n",
    "        end\n",
    "        counter.single_reward = 0.0\n",
    "        counter.single_reward_d = 0.0\n",
    "        counter.single_speed = 0.0\n",
    "        counter.single_time = 0.0\n",
    "    end\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 1.0:0.2:4.0\n",
    "log_path = string(path,\"AxisLength/\")\n",
    "scene, models, roadway = initialize_env()\n",
    "for alpha in alphas\n",
    "    println(\"alpha: \",alpha)\n",
    "    for pname in pnames\n",
    "        println(pname)\n",
    "        policy_path = string(path,\"Policy/\",pname,\".pkl\")\n",
    "        pc[:reset_policy](policy_path=policy_path)\n",
    "        N = 200\n",
    "\n",
    "        counter = Counter(N)\n",
    "        car_a = alpha*CAR_A/AXLE_DISTANCE\n",
    "        car_b = alpha*CAR_B/AXLE_DISTANCE\n",
    "        rand_ego!(scene,models,roadway,car_a=car_a,car_b=car_b)\n",
    "        pc[:resetPolicy](1)\n",
    "        while !counter.done\n",
    "            handle_action!(pc,scene,models,roadway,counter,true)\n",
    "        end\n",
    "        println(counter.avg_reward)\n",
    "        println(counter.rate_collision)\n",
    "\n",
    "        writedlm(string(log_path,pname,\"_rewards_axis\",alpha,\".txt\"),counter.rewards)\n",
    "        writedlm(string(log_path,pname,\"_rewards_d_axis\",alpha,\".txt\"),counter.rewards_d)\n",
    "        writedlm(string(log_path,pname,\"_speeds_axis\",alpha,\".txt\"),counter.speeds)\n",
    "        writedlm(string(log_path,pname,\"_collision_rate_axis\",alpha,\".txt\"),counter.rate_collision)\n",
    "#         writedlm(string(log_path,pname,\"_time_between_collisions_pareto\",alpha,\".txt\"),(counter.total_time+counter2.total_time)/(counter.num_collision+counter2.num_collision))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
